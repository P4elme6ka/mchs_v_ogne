{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xarray\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCEP Dataset\n",
    "\n",
    "Погодные данные из проекта [NCEP Reanalysis 2](https://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis2.html) — усреднённые за день температура воздуха, относительная влажность и компоненты ветра. Данные можно получить с 1979 года.\n",
    "\n",
    "Загрузите наборы данных в каталог `data/ncep`:\n",
    "- https://www.esrl.noaa.gov/psd/thredds/fileServer/Datasets/ncep/air.2018.nc\n",
    "- https://www.esrl.noaa.gov/psd/thredds/fileServer/Datasets/ncep/uwnd.2018.nc\n",
    "- https://www.esrl.noaa.gov/psd/thredds/fileServer/Datasets/ncep/rhum.2018.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/conventions.py:401: SerializationWarning: variable 'air' has multiple fill values {-99, 32767}, decoding all values to NaN.\n",
      "  stack_char_dim=stack_char_dim, use_cftime=use_cftime)\n",
      "/usr/local/lib/python3.7/site-packages/xarray/conventions.py:401: SerializationWarning: variable 'uwnd' has multiple fill values {-99, 32767}, decoding all values to NaN.\n",
      "  stack_char_dim=stack_char_dim, use_cftime=use_cftime)\n",
      "/usr/local/lib/python3.7/site-packages/xarray/conventions.py:401: SerializationWarning: variable 'rhum' has multiple fill values {-99, 32767}, decoding all values to NaN.\n",
      "  stack_char_dim=stack_char_dim, use_cftime=use_cftime)\n"
     ]
    }
   ],
   "source": [
    "ncep_data = []\n",
    "year = 2018\n",
    "for var in ('air', 'uwnd', 'rhum'):\n",
    "    dataset_filename = 'data/ncep/{}.{}.nc'.format(var, year)\n",
    "    ncep_data.append(xarray.open_dataset(dataset_filename))\n",
    "ncep_data = xarray.merge(ncep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набор признаков на основе данных NCEP\n",
    "\n",
    "Ищем наиболее близкий к точке узел сетки в наборе NCEP, в качестве признаков значения переменных зарегистрированные в день регистрации точки и агрегированные показатели за период от 1 до 3х недель до момента регистрации точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(row):\n",
    "    point = ncep_data.sel(\n",
    "        lon=row['longitude'],\n",
    "        lat=row['latitude'],\n",
    "        level=1000,\n",
    "        method='nearest',\n",
    "    )\n",
    "\n",
    "    p1w = point.rolling(time=7).mean()\n",
    "    p2w = point.rolling(time=14).mean()\n",
    "    p3w = point.rolling(time=21).mean()\n",
    "    \n",
    "    date = row['date']\n",
    "    v = point.sel(time=date)\n",
    "    v1w = p1w.sel(time=date)\n",
    "    v2w = p2w.sel(time=date)\n",
    "    v3w = p3w.sel(time=date)\n",
    "    \n",
    "    return {\n",
    "        'fire_type': row['fire_type'],\n",
    "        'fire_type_name': row['fire_type_name'],\n",
    "        'date': row['date'], \n",
    "        'temperature': v.air.values.item(0),\n",
    "        'humidity': v.rhum.values.item(0),\n",
    "        'uwind': v.uwnd.values.item(0),\n",
    "        't1w': v1w.air.values.item(0),\n",
    "        't2w': v2w.air.values.item(0),\n",
    "        't3w': v3w.air.values.item(0),\n",
    "        'h1w': v1w.rhum.values.item(0),\n",
    "        'h2w': v2w.rhum.values.item(0),\n",
    "        'h3w': v3w.rhum.values.item(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выборка для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9dd263edf240e59f49c653c660ee81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pandas.read_csv('data/wildfires_train.csv')\n",
    "df_subsample = df_train.query('(date > \"2018\") & (date < \"2019\")').sample(n=2000)\n",
    "\n",
    "df_features = []\n",
    "for i, row in tqdm(df_subsample.iterrows(), total=df_subsample.shape[0]):\n",
    "    features = extract_features(row)\n",
    "    df_features.append(features)\n",
    "df_features = pandas.DataFrame(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.iloc[:, 3:].fillna(0)\n",
    "y = df_features['fire_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_classifier = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44691358, 0.49875931, 0.4375    , 0.4559194 , 0.44810127])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    fire_classifier, \n",
    "    X, y, \n",
    "    cv=5, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение для отправки в систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('solution/model.pickle', 'wb') as fout:\n",
    "    pickle.dump(fire_classifier, fout, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_1_prob</th>\n",
       "      <th>fire_2_prob</th>\n",
       "      <th>fire_3_prob</th>\n",
       "      <th>fire_4_prob</th>\n",
       "      <th>fire_5_prob</th>\n",
       "      <th>fire_6_prob</th>\n",
       "      <th>fire_8_prob</th>\n",
       "      <th>fire_9_prob</th>\n",
       "      <th>fire_10_prob</th>\n",
       "      <th>fire_11_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.061281</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.264281</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.034329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.926914</td>\n",
       "      <td>0.012161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.151995</td>\n",
       "      <td>0.036744</td>\n",
       "      <td>0.745223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.590062</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>0.119299</td>\n",
       "      <td>0.129594</td>\n",
       "      <td>0.081595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.248328</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>0.169094</td>\n",
       "      <td>0.467566</td>\n",
       "      <td>0.048927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fire_1_prob  fire_2_prob  fire_3_prob  fire_4_prob  fire_5_prob  \\\n",
       "0     0.001925     0.000094     0.061281     0.009380     0.000272   \n",
       "1     0.000205     0.000022     0.003723     0.020655     0.000044   \n",
       "2     0.002121     0.000045     0.025576     0.004506     0.000302   \n",
       "3     0.001022     0.000102     0.028525     0.031514     0.000301   \n",
       "4     0.001839     0.000350     0.014385     0.030361     0.002830   \n",
       "\n",
       "   fire_6_prob  fire_8_prob  fire_9_prob  fire_10_prob  fire_11_prob  \n",
       "0     0.056167     0.028427     0.264281      0.543845      0.034329  \n",
       "1     0.021186     0.003565     0.011526      0.926914      0.012161  \n",
       "2     0.026830     0.006658     0.151995      0.036744      0.745223  \n",
       "3     0.590062     0.017985     0.119299      0.129594      0.081595  \n",
       "4     0.248328     0.016319     0.169094      0.467566      0.048927  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = pandas.DataFrame(\n",
    "    fire_classifier.predict_proba(X),\n",
    "    index=df_features.index,\n",
    "    columns=[\n",
    "        'fire_{}_prob'.format(class_id)\n",
    "        for class_id in fire_classifier.classes_\n",
    "    ],\n",
    ")\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv('data/sample_predictions.csv', index_label='point_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
